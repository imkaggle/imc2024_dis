{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "593c7521",
   "metadata": {
    "papermill": {
     "duration": 0.006061,
     "end_time": "2024-05-28T18:22:23.949973",
     "exception": false,
     "start_time": "2024-05-28T18:22:23.943912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## IMC24 Starter for Image Matching Challenge 2024 Hexathlon.\n",
    "\n",
    "IMC24 Starter came to existance thanks to [imc-understanding-the-baseline][1]. The metric score for mean average accuracy came from [IMC2024-3D-metric-evaluation-example][2].<br>\n",
    "To further modify the code for submission and scoring, the utility script can be accessed [here][3].\n",
    "\n",
    "[1]: https://www.kaggle.com/code/asarvazyan/imc-understanding-the-baseline\n",
    "[2]: https://www.kaggle.com/code/fabiobellavia/imc2024-3d-metric-evaluation-example\n",
    "[3]: https://www.kaggle.com/code/nartaa/imc24"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d175cf",
   "metadata": {
    "papermill": {
     "duration": 0.005148,
     "end_time": "2024-05-28T18:22:23.960728",
     "exception": false,
     "start_time": "2024-05-28T18:22:23.955580",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SETUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cca9ea47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T18:22:23.972892Z",
     "iopub.status.busy": "2024-05-28T18:22:23.972515Z",
     "iopub.status.idle": "2024-05-28T18:23:29.684150Z",
     "shell.execute_reply": "2024-05-28T18:23:29.683193Z"
    },
    "papermill": {
     "duration": 65.720308,
     "end_time": "2024-05-28T18:23:29.686380",
     "exception": false,
     "start_time": "2024-05-28T18:22:23.966072",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imc24 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9246699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T18:23:29.700007Z",
     "iopub.status.busy": "2024-05-28T18:23:29.699700Z",
     "iopub.status.idle": "2024-05-28T18:23:30.801639Z",
     "shell.execute_reply": "2024-05-28T18:23:30.800272Z"
    },
    "papermill": {
     "duration": 1.111549,
     "end_time": "2024-05-28T18:23:30.804273",
     "exception": false,
     "start_time": "2024-05-28T18:23:29.692724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -r /kaggle/input/disambiguation disambiguation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ecf37e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T18:23:30.822109Z",
     "iopub.status.busy": "2024-05-28T18:23:30.821734Z",
     "iopub.status.idle": "2024-05-28T18:23:30.828173Z",
     "shell.execute_reply": "2024-05-28T18:23:30.827162Z"
    },
    "papermill": {
     "duration": 0.016384,
     "end_time": "2024-05-28T18:23:30.830384",
     "exception": false,
     "start_time": "2024-05-28T18:23:30.814000",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/kaggle/input/disambiguation\")\n",
    "sys.path.append(\"/kaggle/working\")\n",
    "\n",
    "all_categories = ['symmetries-and-repeats', 'historical_preservation', 'air-to-ground', 'day-night', 'temporal', 'historical_preservation', 'nature', 'transparent']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320c41a4",
   "metadata": {
    "papermill": {
     "duration": 0.005641,
     "end_time": "2024-05-28T18:23:30.841594",
     "exception": false,
     "start_time": "2024-05-28T18:23:30.835953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SIMILLIAR PAIRS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6efbe8da",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T18:23:30.854123Z",
     "iopub.status.busy": "2024-05-28T18:23:30.853842Z",
     "iopub.status.idle": "2024-05-28T18:23:30.866094Z",
     "shell.execute_reply": "2024-05-28T18:23:30.865248Z"
    },
    "papermill": {
     "duration": 0.020977,
     "end_time": "2024-05-28T18:23:30.868048",
     "exception": false,
     "start_time": "2024-05-28T18:23:30.847071",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pairs(images_list,device=DEVICE):\n",
    "    if EXHAUSTIVE:\n",
    "        return list(combinations(range(len(images_list)), 2)) \n",
    "    \n",
    "    processor = AutoImageProcessor.from_pretrained('/kaggle/input/dinov2/pytorch/base/1/')\n",
    "    model = AutoModel.from_pretrained('/kaggle/input/dinov2/pytorch/base/1/').eval().to(DEVICE)\n",
    "    embeddings = []\n",
    "    \n",
    "    for img_path in images_list:\n",
    "        image = K.io.load_image(img_path, K.io.ImageLoadType.RGB32, device=DEVICE)[None, ...]\n",
    "        with torch.inference_mode():\n",
    "            inputs = processor(images=image, return_tensors=\"pt\", do_rescale=False ,do_resize=True, \n",
    "                               do_center_crop=True, size=224).to(DEVICE)\n",
    "            outputs = model(**inputs)\n",
    "            embedding = F.normalize(outputs.last_hidden_state.max(dim=1)[0])\n",
    "        embeddings.append(embedding)\n",
    "        \n",
    "    embeddings = torch.cat(embeddings, dim=0)\n",
    "    distances = torch.cdist(embeddings,embeddings).cpu()\n",
    "    distances_ = (distances <= DISTANCES_THRESHOLD).numpy()\n",
    "    np.fill_diagonal(distances_,False)\n",
    "    z = distances_.sum(axis=1)\n",
    "    idxs0 = np.where(z == 0)[0]\n",
    "    for idx0 in idxs0:\n",
    "        t = np.argsort(distances[idx0])[1:MIN_PAIRS]\n",
    "        distances_[idx0,t] = True\n",
    "        \n",
    "    s = np.where(distances >= TOLERANCE)\n",
    "    distances_[s] = False\n",
    "    \n",
    "    idxs = []\n",
    "    for i in range(len(images_list)):\n",
    "        for j in range(len(images_list)):\n",
    "            if distances_[i][j]:\n",
    "                idxs += [(i,j)] if i<j else [(j,i)]\n",
    "    \n",
    "    idxs = list(set(idxs))\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40689461",
   "metadata": {
    "papermill": {
     "duration": 0.005296,
     "end_time": "2024-05-28T18:23:30.878947",
     "exception": false,
     "start_time": "2024-05-28T18:23:30.873651",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# KEYPOINTS EXTRACTOR AND MATCHER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b6613564",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T18:23:30.891722Z",
     "iopub.status.busy": "2024-05-28T18:23:30.891365Z",
     "iopub.status.idle": "2024-05-28T18:23:30.904552Z",
     "shell.execute_reply": "2024-05-28T18:23:30.903677Z"
    },
    "papermill": {
     "duration": 0.022108,
     "end_time": "2024-05-28T18:23:30.906476",
     "exception": false,
     "start_time": "2024-05-28T18:23:30.884368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def keypoints_matches(images_list,pairs, categories):\n",
    "#     images_list_sorted = sorted(images_list)\n",
    "\n",
    "    extractor = ALIKED(max_num_keypoints=MAX_NUM_KEYPOINTS,detection_threshold=DETECTION_THRESHOLD,resize=RESIZE_TO).eval().to(DEVICE)\n",
    "    matcher = KF.LightGlueMatcher(\"aliked\", {'width_confidence':-1, 'depth_confidence':-1, 'mp':True if 'cuda' in str(DEVICE) else False}).eval().to(DEVICE)\n",
    "    rotation = create_model(\"swsl_resnext50_32x4d\").eval().to(DEVICE)\n",
    "    \n",
    "    with h5py.File(\"keypoints.h5\", mode=\"w\") as f_kp, h5py.File(\"descriptors.h5\", mode=\"w\") as f_desc:  \n",
    "        for image_path in images_list:\n",
    "            with torch.inference_mode():\n",
    "                image = load_image(image_path).to(DEVICE)\n",
    "                feats = extractor.extract(image)\n",
    "                f_kp[image_path.name] = feats[\"keypoints\"].squeeze().cpu().numpy()\n",
    "                f_desc[image_path.name] = feats[\"descriptors\"].squeeze().detach().cpu().numpy()\n",
    "                \n",
    "    with h5py.File(\"keypoints.h5\", mode=\"r\") as f_kp, h5py.File(\"descriptors.h5\", mode=\"r\") as f_desc, \\\n",
    "         h5py.File(\"matches.h5\", mode=\"w\") as f_matches:  \n",
    "        for pair in pairs:\n",
    "            key1, key2 = images_list[pair[0]].name, images_list[pair[1]].name\n",
    "            \n",
    "#             idx1 = images_list_sorted.index(images_list[pair[0]])\n",
    "#             idx2 = images_list_sorted.index(images_list[pair[1]])\n",
    "#             print(idx1, idx2)\n",
    "#             if abs(idx1 - idx2)>10 and (\"symmetries-and-repeats\" in categories and 'transparent' not in categories):\n",
    "#                      continue\n",
    "            kp1 = torch.from_numpy(f_kp[key1][...]).to(DEVICE)\n",
    "            kp2 = torch.from_numpy(f_kp[key2][...]).to(DEVICE)\n",
    "            desc1 = torch.from_numpy(f_desc[key1][...]).to(DEVICE)\n",
    "            desc2 = torch.from_numpy(f_desc[key2][...]).to(DEVICE)\n",
    "            with torch.inference_mode():\n",
    "                _, idxs = matcher(desc1, desc2, KF.laf_from_center_scale_ori(kp1[None]), KF.laf_from_center_scale_ori(kp2[None]))\n",
    "            if len(idxs): group = f_matches.require_group(key1)\n",
    "            if len(idxs) >= MIN_MATCHES: group.create_dataset(key2, data=idxs.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01f916cf",
   "metadata": {
    "papermill": {
     "duration": 0.005149,
     "end_time": "2024-05-28T18:23:30.917087",
     "exception": false,
     "start_time": "2024-05-28T18:23:30.911938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RANSAC AND SPARSE RECONSTRUCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e38d9dc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T18:23:30.930603Z",
     "iopub.status.busy": "2024-05-28T18:23:30.930107Z",
     "iopub.status.idle": "2024-05-28T18:23:30.940554Z",
     "shell.execute_reply": "2024-05-28T18:23:30.939665Z"
    },
    "papermill": {
     "duration": 0.019859,
     "end_time": "2024-05-28T18:23:30.942546",
     "exception": false,
     "start_time": "2024-05-28T18:23:30.922687",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ransac_and_sparse_reconstruction(images_path, categories):\n",
    "    now = datetime.datetime.now()\n",
    "    time_str = now.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    db_name = f'colmap_{time_str}.db'\n",
    "    db = COLMAPDatabase.connect(db_name)\n",
    "    db.create_tables()\n",
    "    fname_to_id = add_keypoints(db, '/kaggle/working/', images_path, '', 'simple-radial', False)\n",
    "    add_matches(db, '/kaggle/working/',fname_to_id)\n",
    "    db.commit()\n",
    "    \n",
    "    \n",
    "    # \n",
    "    if \"symmetries-and-repeats\" in categories and 'transparent' not in categories:\n",
    "        print(\"remove disambiguation ing\")\n",
    "        from disambiguation import calculate_geodesic_consistency_scores_fn\n",
    "#         from disambiguation import calculate_missing_correspondences_scores_fn\n",
    "        from disambiguation.utils.read_write_database import remove_matches_from_db\n",
    "        \n",
    "        scores = calculate_geodesic_consistency_scores_fn(None, old_db_path=Path(db_name), \n",
    "                                                          track_degree=3, \n",
    "                                                          coverage_thres=0.7, alpha=0.1, \n",
    "                                                          minimal_views=4, ds = \"largearray\")\n",
    "        \n",
    "#         scores = calculate_missing_correspondences_scores_fn(None, old_db_path=Path(db_name), score_version=2)\n",
    "#         thres = 0.1\n",
    "                                             \n",
    "        thres = 0.05\n",
    "        valid = scores >= thres\n",
    "        invalid = np.logical_not(valid)\n",
    "        scores[invalid] = 0.0\n",
    "        new_db_name = Path(db_name.replace(\".db\", \"_new_database.db\"))\n",
    "        remove_matches_from_db(Path(db_name), new_db_name, Path(\"tmp_match.txt\"), valid)\n",
    "        db_name = new_db_name\n",
    "\n",
    "    # \n",
    "    \n",
    "    \n",
    "    pycolmap.match_exhaustive(db_name, sift_options={'num_threads':1})\n",
    "    maps = pycolmap.incremental_mapping(\n",
    "        database_path=db_name, \n",
    "        image_path=images_path,\n",
    "        output_path='/kaggle/working/', \n",
    "        options=pycolmap.IncrementalPipelineOptions({'min_model_size':MIN_MODEL_SIZE, 'max_num_models':MAX_NUM_MODELS, 'num_threads':1})\n",
    "    )\n",
    "    return maps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3feea0",
   "metadata": {
    "papermill": {
     "duration": 0.005137,
     "end_time": "2024-05-28T18:23:30.953212",
     "exception": false,
     "start_time": "2024-05-28T18:23:30.948075",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# HYPERPARAMETER TUNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dfed0575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T18:23:30.965418Z",
     "iopub.status.busy": "2024-05-28T18:23:30.965162Z",
     "iopub.status.idle": "2024-05-28T18:23:30.970357Z",
     "shell.execute_reply": "2024-05-28T18:23:30.969488Z"
    },
    "papermill": {
     "duration": 0.013737,
     "end_time": "2024-05-28T18:23:30.972479",
     "exception": false,
     "start_time": "2024-05-28T18:23:30.958742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SIMILLIAR PAIRS\n",
    "EXHAUSTIVE = True\n",
    "MIN_PAIRS = 50\n",
    "DISTANCES_THRESHOLD = 0.3\n",
    "TOLERANCE = 500\n",
    "\n",
    "# KEYPOINTS EXTRACTOR AND MATCHER\n",
    "MAX_NUM_KEYPOINTS = 4096\n",
    "RESIZE_TO = 1280\n",
    "DETECTION_THRESHOLD = 0.005\n",
    "MIN_MATCHES = 100\n",
    "\n",
    "# RANSAC AND SPARSE RECONSTRUCTION\n",
    "MIN_MODEL_SIZE = 5\n",
    "MAX_NUM_MODELS = 3\n",
    "\n",
    "# CROSS VALIDATION\n",
    "N_SAMPLES = 50\n",
    "\n",
    "SUBMISSION = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e839bb",
   "metadata": {
    "papermill": {
     "duration": 0.005433,
     "end_time": "2024-05-28T18:23:30.983469",
     "exception": false,
     "start_time": "2024-05-28T18:23:30.978036",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## CROSS VALIDATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f768ad2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T18:23:30.995943Z",
     "iopub.status.busy": "2024-05-28T18:23:30.995666Z",
     "iopub.status.idle": "2024-05-28T18:23:31.004990Z",
     "shell.execute_reply": "2024-05-28T18:23:31.004085Z"
    },
    "papermill": {
     "duration": 0.017656,
     "end_time": "2024-05-28T18:23:31.006917",
     "exception": false,
     "start_time": "2024-05-28T18:23:30.989261",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "if not SUBMISSION:\n",
    "    def image_path(row):\n",
    "        row['image_path'] = 'train/' + row['dataset'] + '/images/' + row['image_name']\n",
    "        return row\n",
    "\n",
    "    train_df = pd.read_csv(f'{IMC_PATH}/train/train_labels.csv')\n",
    "    train_df = train_df.apply(image_path,axis=1).drop_duplicates(subset=['image_path'])\n",
    "    G = train_df.groupby(['dataset','scene'])['image_path']\n",
    "    image_paths = []\n",
    "    \n",
    "    for g in G:\n",
    "        n = N_SAMPLES\n",
    "        n = n if n < len(g[1]) else len(g[1])\n",
    "        g = g[0],g[1].sample(n,random_state=42).reset_index(drop=True)\n",
    "        for image_path in g[1]:\n",
    "            image_paths.append(image_path)\n",
    "        \n",
    "    gt_df = train_df[train_df.image_path.isin(image_paths)].reset_index(drop=True)\n",
    "    pred_df = gt_df[['image_path','dataset','scene','rotation_matrix','translation_vector']]\n",
    "    pred_df.to_csv('pred_df.csv',index=False)\n",
    "    run('pred_df.csv', get_pairs, keypoints_matches, ransac_and_sparse_reconstruction, submit=False)\n",
    "    pred_df = pd.read_csv('submission.csv')\n",
    "    mAA = round(score(gt_df, pred_df),4)\n",
    "    print('*** Total mean Average Accuracy ***')\n",
    "    print(f\"mAA: {mAA}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5f867c",
   "metadata": {
    "papermill": {
     "duration": 0.005265,
     "end_time": "2024-05-28T18:23:31.017623",
     "exception": false,
     "start_time": "2024-05-28T18:23:31.012358",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# SUBMISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87443d1d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T18:23:31.029872Z",
     "iopub.status.busy": "2024-05-28T18:23:31.029563Z",
     "iopub.status.idle": "2024-05-28T18:23:31.046095Z",
     "shell.execute_reply": "2024-05-28T18:23:31.045179Z"
    },
    "papermill": {
     "duration": 0.024838,
     "end_time": "2024-05-28T18:23:31.048128",
     "exception": false,
     "start_time": "2024-05-28T18:23:31.023290",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_parse_sample_submission(data_path):\n",
    "    data_dict = {}\n",
    "    categories_dict = {}\n",
    "    with open(data_path / \"sample_submission.csv\", \"r\") as f:\n",
    "        for i, l in enumerate(f):\n",
    "            if i == 0:\n",
    "                print(\"header:\", l)\n",
    "\n",
    "            if l and i > 0:\n",
    "                image_path, dataset, scene, _, _ = l.strip().split(',')\n",
    "                if dataset not in data_dict:\n",
    "                    data_dict[dataset] = {}\n",
    "                if scene not in data_dict[dataset]:\n",
    "                    data_dict[dataset][scene] = []\n",
    "                data_dict[dataset][scene].append(Path(IMC_PATH +'/'+ image_path))\n",
    "                \n",
    "    with open(data_path / \"test/categories.csv\", \"r\") as f:\n",
    "        for i, l in enumerate(f):\n",
    "            # Skip header\n",
    "            if i == 0:\n",
    "                print(\"header:\", l)\n",
    "\n",
    "            if l and i > 0:\n",
    "                scene, categories = l.strip().split(',')\n",
    "                categories_dict[scene] = categories\n",
    "    for dataset in data_dict:\n",
    "        for scene in data_dict[dataset]:\n",
    "            print(f\"{dataset} / {scene} -> {len(data_dict[dataset][scene])} images\")\n",
    "\n",
    "    return data_dict, categories_dict\n",
    "\n",
    "def my_run(data_path,get_pairs,keypoints_matches,ransac_and_sparse_reconstruction,submit=True):\n",
    "    results = {}\n",
    "    \n",
    "    data_dict, categories_dict = my_parse_sample_submission(data_path)\n",
    "    datasets = list(data_dict.keys())\n",
    "    \n",
    "    for dataset in datasets:\n",
    "        if dataset not in results:\n",
    "            results[dataset] = {}\n",
    "            \n",
    "        for scene in data_dict[dataset]:\n",
    "            images_dir = data_dict[dataset][scene][0].parent\n",
    "            results[dataset][scene] = {}\n",
    "            image_paths = data_dict[dataset][scene]\n",
    "            categories = categories_dict[scene]\n",
    "            index_pairs = get_pairs(image_paths)\n",
    "            keypoints_matches(image_paths, index_pairs, categories)                \n",
    "            maps = ransac_and_sparse_reconstruction(image_paths[0].parent, categories)\n",
    "            clear_output(wait=False)\n",
    "            \n",
    "            path = 'test' if submit else 'train'\n",
    "            images_registered  = 0\n",
    "            best_idx = 0\n",
    "            for idx, rec in maps.items():\n",
    "                if len(rec.images) > images_registered:\n",
    "                    images_registered = len(rec.images)\n",
    "                    best_idx = idx\n",
    "            print(\"maps:\", maps)\n",
    "            for k, im in maps[best_idx].images.items():\n",
    "                key = Path(IMC_PATH) / path / scene / \"images\" / im.name\n",
    "                results[dataset][scene][key] = {}\n",
    "                results[dataset][scene][key][\"R\"] = deepcopy(im.cam_from_world.rotation.matrix())\n",
    "                results[dataset][scene][key][\"t\"] = deepcopy(np.array(im.cam_from_world.translation))\n",
    "\n",
    "            create_submission(results, data_dict, Path(IMC_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e8fcd",
   "metadata": {
    "papermill": {
     "duration": 0.005264,
     "end_time": "2024-05-28T18:23:31.059274",
     "exception": false,
     "start_time": "2024-05-28T18:23:31.054010",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e790d889",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-28T18:23:31.071710Z",
     "iopub.status.busy": "2024-05-28T18:23:31.071360Z",
     "iopub.status.idle": "2024-05-28T18:31:29.852883Z",
     "shell.execute_reply": "2024-05-28T18:31:29.851797Z"
    },
    "papermill": {
     "duration": 478.790093,
     "end_time": "2024-05-28T18:31:29.854952",
     "exception": false,
     "start_time": "2024-05-28T18:23:31.064859",
     "status": "completed"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maps: {0: Reconstruction(num_reg_images=37, num_cameras=37, num_points3D=12504, num_observations=65426)}\n"
     ]
    }
   ],
   "source": [
    "if SUBMISSION:\n",
    "    data_path = IMC_PATH\n",
    "    my_run(Path(data_path), get_pairs, keypoints_matches, ransac_and_sparse_reconstruction)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 8143495,
     "sourceId": 71885,
     "sourceType": "competition"
    },
    {
     "datasetId": 4628051,
     "sourceId": 7884485,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4628331,
     "sourceId": 7884725,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5071680,
     "sourceId": 8517790,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 172469456,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 173217852,
     "sourceType": "kernelVersion"
    },
    {
     "modelInstanceId": 3326,
     "sourceId": 4534,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 14317,
     "sourceId": 17191,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelInstanceId": 14611,
     "sourceId": 17555,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30683,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 551.384343,
   "end_time": "2024-05-28T18:31:32.581079",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-28T18:22:21.196736",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
